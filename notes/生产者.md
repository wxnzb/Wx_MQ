### 生产者
kafka自定义了一套网络协议，遵守这个协议的格式，就可以像kafka推送消息或者拉取消息
kafka生产者主要实现的功能：
- 同步/异步发送消息
- 批量发送消息
- 超时重发
#### 生产者代码步骤
- 1.明确发送时同步还是异步；2.明确kafka服务端的主机名和端口号；3.明确发送的topic;4.循环分析：要是异步发送，生产者发送消息给kafka服务端，然后忙自己的事，收到服务端发来的ack确认消息后，会调用回调函数；同步机制：生产者发送消息给kafka服务端，阻塞等待，收到服务端发来的ack确认消息后，会调用回调函数
- 具体过程：消息发送过程，涉及两个线程协同工作
- 主线程：将数据封装成ProducerRecord对象，调用send()将消息存在RecordAccumulator中
- Sender线程：从 RecordAccumulator 中不断拉取数据并发送到 Kafka，并进行响应处理
从RecordAccoumulator中批量取出消息(都是同一topic+分区)构成ProducerBatch,取出多个ProducerBatch封装成ClientRequest，将ClientRequest交给NetworkClient,NetworkClient将请求通过kafkachannel执行I/O线程批量发送给broker，收到响应后，调用ClientRequest的回调函数
#### kafkaProducer
- 实现了四个方法
```
//1
send()将消息存入RecordAccumulator
//2
flush(),等待RecordAccumulator中的消息发送完全
//3
partitionsFor(),从Metadata(存储kafka集群的元信息)中获取制定Topic的分区信息
//4
close()关闭Producer对象，等待RecordAccumulator清空，关闭Sender线程
```
- 重要字段解释(cv)
```
PRODUCER_CLIENT_ID_SEQUENCE：clientId的生成器
clientId：此生产者的唯一标识
partitioner：分区选择器
maxRequestSize：消息的最大长度,包含消息头
totalMemorySize：发送单个消息的缓冲区大小
accumulator：RecordAccumulator
sender：发送消息的Sender任务
ioThread：执行Sender任务发送消息的线程
compressionType：压缩算法
keySerializer：key的序列化器
valueSerializer：value的序列化器
Metadata metadata：整个Kafka集群的元数据
maxBlockTimeMs：等待更新Kafka集群元数据的最大时长
requestTimeoutMs：从消息发送到收到ACK响应的最长时长
interceptors：ProducerInterceptor集合，ProducerInterceptor可以在消息发送之前对其进行拦截或修改；也可以先于用户的Callback，对ACK响应进行预处理producerConfig：配置对象，使用反射初始化KafkaProducer配置的相对对象
```
- 为什么要在kafkaProducer中维护kafka集群的元信息
- 在创建ProducerRecord时，只需指定topic的名称，那么他是怎样去特定的分区的，那么就是元信息中存储着这个topic对应几个分区，经过特定算法可以知道目标分区，那么最终时需要知道目标分区的leader所在服务器的地址，端口，这些信息也存在元信息里面
- 元信息具体数据（可以理解为通过结构体存储信息）
```
//Node表示一个集群的节点broker,Node记录这个节点host,ip,port
type Node struct {
    ID   int
    Host string
    Port int
    ...
}
//TopicPartition表示某个topic的分区，里面有topic名称，这个分区在这个topic的编号id
type TopicPartition struct {
    Topic     string
    Partition int
    ...
}
//PartitionInfo:分区详细信息，里面有topic string,partition int[和上面一样]，还有leader Node[leader所在节点的id],replicas Node[]-所有副本所在的节点信息，inSyncReplicas-isr集合中所有节点信息
type PartitionInfo struct {
    Topic           string
    Partition       int
    Leader          Node
    Replicas        []Node
    InSyncReplicas  []Node
    ...
}
```
- 这些信息都包含在cluster集群中，这个cluster核心字段如下：
- 1.nodes:kafka集群中节点列表（[]Node)
- 2.nodesById:  BrokerId<->Node  (map(int,Node))
- 3.partitionByTopicPartition:TopicPartition<->PartitionInfo(map(TopicPartition,PartitionInfo))
- 4.partitionsByTopic:Topic名字<->PartitionInfo(map(string,[]PartitionInfo))
- 5.avaliablePartitionsByTopic:Topic名字<->PartitionInfo(map(string,[]PartitionInfo))
- partitionsByTopic和avaliablePartitionsByTopic的区别是上面那个可以没有leader【在某些中间状态，leader宕机状态】，下面那个必须有leader
- 6.partitionsByNode:Node<->Partitioninfo(map(int,[]PartitionInfo))
##### 这些怎样用呢？1.查找所有broker的信息；2.通过broker的id找到他的Node信息;3.通过TopicPartition找到更加具体的PartitionInfo；4.找到topic下面的所有分区信息(可以是中间状态)；5.找到topic下面的所有分区信息(必须有leader)；6.找到broker这个下面的所有分区信息

#### Metadata封装了cluster，核心字段如下
- topics:所有topic
- version:cluseter集群版本号，每更新一次集群就会使他+1
- metadaExpireMs:更新集群元信息间隔
- refreshBackoffMs:两次更新集群元信息最小间隔
- lastRefreshMa:上次更新元数据时间(失败和成功都包含)
- lastSuccessfulRefreshMs:上次元数据更新成功时间
- cluster:kafka集群元数据记录
- needUpdate:是否强制更新元数据-还不太懂
- listeners:监听Metadata更新的监听器集合-还不太懂
- needMetadaForTopics:是否更新全部的topic的元数据
-------------------------------------------------------------------
####  Metadata核心方法
```
//将needUpdate更新为true,目的：Sender线程运行时更新Metadata记录的元数据，然会version的值
requestUpdate()
//通过version版本号来判断元数据是否更新成功，要是没有就阻塞
awaitUpdate()
```
#### Metadata中的字段由主线程读取，Sender线程负责更新，因此必须要保证线程安全性，因此一般都要给他配置sync
#### waitOnMetadata()函数分析
- 看自己需要的topic是否在Metadata里面，要是没在，就加进去
- 获取topic中分区的详细信息，要是失败，调用requestUpdate()，唤醒Sender线程，使得Sender线程更新Metadata记录的元数据
- 主线程调用awaitUpdate()，等待Sender线程更新元数据成功
- 回到第二步直到获取partitioninfo分区信息成功

--------------------------------------------------------------------------------------------------------------------

#### Serializer和Deserializer是将对象序列化或者反序列化为[]byte，因为客户端发送的消息(key+value)都得是[]byte
- 在主线程：将数据封装成ProducerRecord对象，调用send()将消息存在RecordAccumulator中执行完这一步的时候，要思考把这个发送到topic【这个ProducerRecord对象包指定了】下面的哪个分区，1,ProducerRecord对象[partition字段]里面写了他自己想去的分区序号；2,没写，那就需要通过Partitioner.partition()去选择一个分区了
- 在创建kafkaproducer时传入的key/value会被保存在abstractConfig的originals字段中，abstractConfig的核心方法时getConfiguredInstance(),这个函数的作用是通过反射机制时理化original字段中指定的类
- 设计Configurable接口的目的是统一反射后的初始化过程，对外提供统一的接口。上面那个方法通过反射构造的对象，都是通过无参构造函数构造的，而现在这个接口的configure()封装对象初始化需要一个originals字段的参数-----没太明白这里是想说明啥
- DefaultPartitioner.partition()是在ProducerRecord没有明确指定分区对象的时候用的，分情况：1：没有key,只有value,根据counter(原子性)和partition个数取模来确定分区【counter不断增加，保证消息不会被分到用一个分区里面】；2：有key,有value,对key使用hash与分区个数进行取模
### RecordAccumlator
- 我们现在了解他里面就是缓存了很多的消息，具体怎样实现的
- 通过map(TopicPartition,ArrayDeque<RecordBath>)来实现，就是前者key是要发往的分区，后者是要发的消息<RecordBatch>的对列，每个RecordBatch拥有一个MemeoryRecords对象的引用，他才是最终缓存消息的地方
######  MemeryRecords表示的是多个消息的集合
##### RecordAccumlator重要字段介绍
- buffer:用于保存数据的地方
- writeLimit:记录buffer字段最多可写入多少字节的数据
- compressor:将消息压缩后输出到buffer
```
//compressor重要字段介绍
- bufferStream:在buffer上建立的ByteBufferOutputStream对象，作用就是当写入消息超过了ByteBuffer容量，ByteBufferOutStream会自动进行扩容
- DataOutPutStream:为前者添加了压缩功能【压缩方法是GZIP,SNAPPY,LZ4,由kafkaProducer的compressionType字段决定】
- Compressor.enstimateBytesWritten()方法通过压缩率，估算因子等来估计已写入的字节，作用：判断MemoryRecords是否写满
```
- writable:设置MemoryRecords模式，在他发送前，设置成只读模式
##### RecordAccumlator重要方法介绍
- append():先判断MemoryRecords是否可写，调用Compressor.put*()方法，将消息写入ByteBuffer中
- hasRoomFor():根据Compressor.enstimateBytesWritten()来估算以写入的字节，来判断是否能容纳值后要写入的数据，要是不行，ByteBuffer就要进行扩容
- close():要是ByteBuffer出现了扩容情况，那么MemoryRecords.buffer和ByteBufferOutStream.buffer将指向不同的ByteBuffer,那么现在close()做两件事：1,就会让他们指向同一个ByteBuffer【通过使MemoryRecords.buffer指向扩容获得ByteBuffer】；2,将writable设置成false
- sizeInBytes():对于可写的MemoryRecords,返回的是ByteBufferOutputStream.buffer字段的大小；对于可读的，返回的是MemoryRecords.buffer的大小
#### RecordBatch（每一个RecordBatch封装了一个MemeryRecords对象)
##### 重要字段介绍
- recordCount:Record的个数
- maxRecordSize:最大Record的字节数
- attempts:尝试发送当前RecordBatch的次数
- lastAttemptMs:最后一次发送RecordBatch的时间
- records:指向MemoryRecords对象
- topicPartition:当前RecordBatch缓存消息发送的目的地
- producerFuture:ProduceRequestResult类型，标记RecordBatch状态的Future对象
```
//1
ProducerFuture通过包含count=1的CountDownLatch实现了Future功能
当RecordBatch中的消息被发送，会调用ProducerRequestResult.done()，将producerFuture标记为完成,,通过ProducerRequestResult.error来判断是否正常发送,然后调用CountDownLatch的down()来唤醒阻塞的await()
//2
ProduceRequestResult中包含重要字段baseOffset,这是第一条消息在RecordBath中的位置，根据他可以退出后面消息的位置
```
- lastAppendTime:最后一次在RecordBatch追加消息的时间
- thunks:Thunk对象的集合
- offsetCounter:记录没个消息在RecordBatch中的偏移量
- retry:要是RecordBatch中数据发送失败，是否继续尝试
###### thunks详解
- kafkaProducer.send()的第二个参数是Callback对象，针对每个消息的回调函数，RecordBatch.thunks就是消息回调对象对列，每一个消息回调对象里面包含Callback字段以及future字段，future字段他是FutureRecordMetadata类型
- FutureRecordMetadata类型包含两个重要字段
- result：ProduceRequestResult类型，指向对应消息所在RecordBatch的produceFuture字段
- relativeOffset:记录该消息在RecordBatch中的偏移量
#### RecordBath核心方法
- tryAppend(),目的：尝试将消息添加到RecordBatch中缓存
- done(),目的：将服务端返回的信息封装成RecordMetadata,调用消息对应的Callback。当生产者受到响应，调用FutureRecordMetadata.get()方法返回他生成的RecordMetadata对象。
#### 这里future来future去的，要是我是读者，可能看的会一脸蒙蔽，没关系的，咱做就把他做好，现在来理理关系哈
- future概念：代表未来某个时间可获取的结果的对象，通俗来说就是未来的结果存储的地方，用于异步编成，先发请求，后取结果
- 为了能在调用send线程先返回一个结果，他就是这样了：Future<RecordMetadata>future=producer.send(record, callback)，这样的话你有两个选择：异步：传入callback,等kafka调用；同步：调用future.get()阻塞等待结果
- 详细步骤如下：
- 在将消息封装成ProducerRecord对象存到RecordAccumlator的时候，同时创建在FutureRecordMetadata：某条消息的发送future，里面包含几个重要元素1:relativeOffset:在RecordBatch中的位置；2：callback:回调函数；3：resule:引用的是ProduceRequestResult
- 在将消息封装成ProducerRecord对象存到RecordAccumlator的时候，（会进行判断，要是存不下，就在创建一个新的RecordBatch），将FutureRecordMetadata加入RecordBatch的thunks队列
- Sender线程从RecordAccumlator拉取可以发送的RecordBatch将他聚合成一个ProduceRequest发送到broker
- broker ack
- 疑问：下面第一个返回的RecoedMetadata着各种不就有callback吗，为什么还要遍历thunks呢？-后面是答案
- kafka调用ProducerRequestResult.done(),他内部调用CountDownLatch(1).countDown()唤醒所有future,所以future.get()返回RecoedMetadata对象-这个是你要是同步调用了feature.get()等待的时候有用
- kafka遍历改RecordBatch的所有thunks,执行所有消息的callback-这个是异步返回结果
- ProduceRequestResult:RecordBatch级别的future(所有消息共享一个)
- CountDownLatch(1):实现了future.get()阻塞等待
- 加油呀，小宝们，你们都很棒呀*>*
------------------------------------------------------------------------------------
## day-3
#### BufferPool
- 产生原因：ByteBuffer的创建和释放都是比较耗费资源的，为了实现内存的高效利用，产生了他。他会对特定大小的ByteBuffer进行管理
##### BufferPool的字段
- free:是一个ArrayDeque<ByteBuffer>队列，缓存指定大小的ByteBuffer对象
- ReentrantLock:因为这个BufferPool在多线程中使用，保证其安全
- waiters:这个队列中包含小空间导致阻塞的线程对应的Condition对象
- totalMemory:整个pool的大小
- availableMemory:可用空间大小-totalMemeoy-free中每个ByteBuffer大小
##### BufferPool的函数
- allocate():从pool中申请ByteBuffer，要是因为空间不足申请不下来的时候，就阻塞调用线程
- deallocate:从pool中释放大小为poolableSize[他是pool队列里面所有ByteBuffer的大小],然后唤醒一个因空间不足而阻塞的线程
#### RecordAccumulator
##### RecordAccumulator字段
- batches:类型CopyOnWriteMap,TopicPartition-RecordBatch集合，他是一个队列，每个队员里面都可以找到RecordBatch集合要发送到的目的地TopicPartition
- BatchSize:指定每个RecordBatch底层的ByteBuffer大小
- Compression：压缩类型
- imcomplete:未发送完成的RecordBatch集合
- free:BufferPool对象
- drainIndex:发送RecordBatch集合一次发不万，他记录的就是下次开始发送的位置
###### kafkaProducer.send()调用的时候，最终内部调用的是RecordAcculator.append()
######  RecordAcculator.append()详细步骤
- 在batch中找TopicPartition对应的RecordBatch集合，要是没有，就创建，并将他添加到batches
- 对Deque加锁（Deque就是RecordBatch集合）
- 调用tryAppend(),想Deque最后一个RecordBatch追加Record(消息)
- 对Deque解锁
- 要是成功：返回RecordAppendResult[内部封装了ProduceRequestRequest]唤醒sender;
- 追加失败：从BufferPool中申请新的ByteBuffer，回到给Deque加锁继续直到追加成功，要是还是失败，就用ByteBuffer创建RecordBatch, 将Record追加到新建的RecordBatch,将RecordBatch追加打破Deque最后将新建的RecordBatch追加到incomplete集合,然后解锁，返回并唤醒sender;
####### 当然，这里唤醒sender也不是说唤醒就能唤醒的，他是调用了kafkaProducer.dosend()函数判断此次向RecordAccumlator中追加消息是否满足消息所在的最后一个RecordBatch满了，或者队列中不指一个RecordBatch
#### Ready()[在客户端向服务器发送消息前，会调用它来获取符合发送的消息集合的节点],有如下条件
- Deque中有多个RecordBatch或者第一个RecordBatch是否满了【只取第一个进行判断就行】
- 是否超时了
- 是否BufferPool的空间耗尽了
- 是否有线程在等待flush操作完成
- sender线程准备关闭
##### 他的过程如下：首先他会遍历batches集合的每分区，找到分区leader所在的node,要是满足上面的条件就加到readyNodes集合中；过程完后最后函数返回ReadyCheckResult对象，他里面记录了满足的node集合，还有直到步道leader的分区，还有下次调用ready()进行检查的时间间隔
##### kafkaProducer.send()调用的时候，最终内部调用的是RecordAcculator.append(),接着调用RecordAccumulator.drain()
###### RecordAccumulator.drain()会将之前的map(TopicPartition,list<RecordBatch>)构造成map(NodeID,List<RecordBatch>)返回
- 为什么要这样做呢？---原因：在I/O层，生产者是面向Node发送消息的，但是在sender呢ubu，他是关关心消息发送到哪个分区的

